---
---

@misc{gao2024outofdistributionrecoveryobjectcentrickeypoint,
  title={Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy For Visuomotor Imitation Learning}, 
  author={Gao, George Jiayuan and Li, Tianyu and Figueroa, Nadia},
  abstract={We propose an object-centric recovery policy framework to address the challenges of out-of-distribution (OOD) scenarios in visuomotor policy learning. Previous behavior cloning (BC) methods rely heavily on a large amount of labeled data coverage, failing in unfamiliar spatial states. Without relying on extra data collection, our approach learns a recovery policy constructed by an inverse policy inferred from object keypoint manifold gradient in the original training data. The recovery policy serves as a simple add-on to any base visuomotor BC policy, agnostic to a specific method, guiding the system back towards the training distribution to ensure task success even in OOD situations. We demonstrate the effectiveness of our object-centric framework in both simulation and real robot experiments, achieving an improvement of 77.7% over the base policy in OOD. },
  year={2024},
  additional_info={:sparkles: <b>Spotlight</b> at *[CoRL Workshop on Lifelong Learning for Home Robots](https://llhomerobots.github.io/)*},
  project_site={https://sites.google.com/view/ocr-penn}, 
  pdf={https://arxiv.org/pdf/2411.03294}, 
  arxiv={2411.03294}, 
  video={https://www.youtube.com/watch?v=-24YYIIPWjM}, 
  selected={true},
  preview={ocr_preview.png},
}

@misc{eureka_manip,
  title={(On-Going) Eureka for Manipulation: Real-World Dexterous Agent via Large-Scale Reinforcement Learning}, 
  year={2025},
  additional_info={Training a skilled manipulation agent with RL in simulation that can zero-shot transfer to the real world is hard. The question is: does this get any easier when we add LLM in the loop and utilize ginormous levels of computing power, such as hundreds of Nvidia's latest generation of data-center GPUs?},
  project={true},
  preview={eureka_manip.png},
}

@misc{vlmgineer,
  title={(On-Going) VLMgineer: Vision-Language-Model Driven Gripper Add-Ons for Universal Manipulation}, 
  year={2025},
  additional_info={Can we give robots the ability to design and use tools to solve problems? This project proposes a pipeline leveraging Vision-Language Models (VLMs) to autonomously generate gripper add-ons, enhancing robots' capabilities to handle infinitely diverse and complex objects and scenarios},
  project={true},
  preview={vlmgineer.png},
}

@misc{novel_view_action_synthesis,
  title={(On-Going) Stable Visuomotor Policy from a Single Demo: Elastic Action Synthesis Data Augmentation}, 
  year={2024},
  additional_info={We propose a methodology that uses our in-house Elastic-Motion-Policy, enabling the training of visuomotor policies with full spatial generalization from only a single demonstration},
  project={true},
  preview={converger.gif},
}



@misc{gdn-act,
  title={Novel Environment Transfer of Visuomotor Policy Via Object-Centric Domain-Randomization}, 
  year={2025},
  month={May},
  additional_info={Proposed <b>GDN-ACT</b>, a novel, scalable approach that enables <b>zero-shot generalization</b> of visuomotor policies across unseen environments, using a pre-trained state-space mapping for object localization},
  pdf={gdn-act.pdf}, 
  project={true},
  preview={gdn-act.png},
}

@misc{gmot,
  title={Modular Gait Optimization: From Unit Moves to Multi-Step Trajectory in Bipedal Systems}, 
  year={2023},
  month={December},
  additional_info={Proposed the Gait Modularization and Optimization Technique (GMOT), which leverages modular <b>unit gaits as initialization</b> for Hybrid Direct Collocation (HDC), reducing sensitivity to constraints and enhancing computational stability across various gaits, including walking, running, and hopping},
  pdf={gmot.pdf}, 
  code={https://github.com/QingquanBao/2DBiped}, 
  project={true},
  preview={gmot.gif},
}

@misc{yvxaiver,
  title={Miniature City Autonomous Driving Platform Development with Real-Time Vision-Based Lane-Following}, 
  year={2023},
  month={May},
  additional_info={Developed the drive stack for Washington University's inaugural miniature city autonomous driving platform by developing the vision-based lane-following pipeline},
  code={https://github.com/ggao22/yvxavier}, 
  project={true},
  preview={yvxaiver.gif},
}

