<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> George Jiayuan Gao </title> <meta name="author" content="George Jiayuan Gao"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8F%A0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ggao22.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">home <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">George</span> Jiayuan Gao </h1> <p class="desc">gegao@seas.upenn.edu</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.png?4550ea1f55beddb73c3cb9ce0145256d" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am a second year Robotics Master’s student in the <a href="https://www.grasp.upenn.edu/" rel="external nofollow noopener" target="_blank">General Robotics, Automation, Sensing &amp; Perception (GRASP) Laboratory</a> at the University of Pennsylvania, advised by <a href="https://nbfigueroa.github.io/" rel="external nofollow noopener" target="_blank">Prof. Nadia Figueroa</a> and <a href="https://www.seas.upenn.edu/~dineshj/" rel="external nofollow noopener" target="_blank">Prof. Dinesh Jayaraman</a>.</p> <p>Previously, I completed my undergraduate studies in Computer Science and Mathematics at Washington University in St. Louis, where I worked with <a href="https://vorobeychik.com/" rel="external nofollow noopener" target="_blank">Prof. Yevgeniy Vorobeychik</a>.</p> <p>My research focuses on the intersection of learning-based methods and control theory for robotics, with the goal of enabling robots to <b>safely</b> and <b>intelligently</b> interact with the physical world.</p> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%67%65%67%61%6F@%73%65%61%73.%75%70%65%6E%6E.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=dCUjGQ0AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/ggao22" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/ggao1" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> </div> <div class="contact-note"></div> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Nov 09, 2024</th> <td> <b>Presented</b> our work on Object-Centric Recovery at CoRL 2024 Workshop on Lifelong Learning for Home Robots. <a href="https://www.youtube.com/watch?v=-24YYIIPWjM&amp;feature=youtu.be" rel="external nofollow noopener" target="_blank">Presentation Video.</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 26, 2024</th> <td> Our paper <a href="https://arxiv.org/abs/2411.03294" rel="external nofollow noopener" target="_blank">“Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy For Visuomotor Imitation Learning”</a> was accepted for <b>Spotlight</b><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> at the <b>CoRL 2024 Workshop on Lifelong Learning for Home Robots</b>. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Publications</a> </h2> <div class="publications"> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ocr_preview-480.webp 480w,/assets/img/publication_preview/ocr_preview-800.webp 800w,/assets/img/publication_preview/ocr_preview-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/ocr_preview.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ocr_preview.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="gao2024outofdistributionrecoveryobjectcentrickeypoint" class="col-sm-8"> <div class="title">Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy For Visuomotor Imitation Learning</div> <div class="author"> <em>George Jiayuan Gao</em>, <a href="http://imtianyuli.com/" rel="external nofollow noopener" target="_blank">Tianyu Li</a>, and <a href="https://nbfigueroa.github.io/" rel="external nofollow noopener" target="_blank">Nadia Figueroa</a> </div> <div class="periodical"> <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <b>Spotlight</b> at <em><a href="https://llhomerobots.github.io/" rel="external nofollow noopener" target="_blank">CoRL Workshop on Lifelong Learning for Home Robots</a></em>, <em>2024</em>. </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2411.03294" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://arxiv.org/pdf/2411.03294" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube.com/watch?v=-24YYIIPWjM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://sites.google.com/view/ocr-penn" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Project Website</a> </div> <div class="abstract hidden"> <p>We propose an object-centric recovery policy framework to address the challenges of out-of-distribution (OOD) scenarios in visuomotor policy learning. Previous behavior cloning (BC) methods rely heavily on a large amount of labeled data coverage, failing in unfamiliar spatial states. Without relying on extra data collection, our approach learns a recovery policy constructed by an inverse policy inferred from object keypoint manifold gradient in the original training data. The recovery policy serves as a simple add-on to any base visuomotor BC policy, agnostic to a specific method, guiding the system back towards the training distribution to ensure task success even in OOD situations. We demonstrate the effectiveness of our object-centric framework in both simulation and real robot experiments, achieving an improvement of 77.7% over the base policy in OOD. </p> </div> </div> </div> </li></ol> </div> <h2> <a href="/publications/" style="color: inherit">Selected Projects</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dsdp-480.webp 480w,/assets/img/publication_preview/dsdp-800.webp 800w,/assets/img/publication_preview/dsdp-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/dsdp.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dsdp.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="novel_view_action_synthesis" class="col-sm-8"> <div class="title">(On-Going) Robust Visuomotor Behavior Cloning Via Novel View Synthesis and Stable Action Synthesis</div> <div class="author"> </div> <div class="periodical"> Proposed pipeline for novel consistent view and stable action generation from single robot demonstration as data-augmentation scheme to enable significantly more data-efficient visuomotor policy learning, <em>2024</em>. </div> <div class="periodical"> </div> <div class="links"> <a href="/projects/novel_view_action_synthesis" class="btn btn-sm z-depth-0" role="button">Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/converger-480.webp 480w,/assets/img/publication_preview/converger-800.webp 800w,/assets/img/publication_preview/converger-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/converger.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="converger.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="latent_converger" class="col-sm-8"> <div class="title">(On-Going) Learning Globally-Latently-Asymptotically Stable Visuomotor Policy</div> <div class="author"> </div> <div class="periodical"> Can vision-based robot policy output actions that converges to some latent attractor? Is it better to separate the learning of latent states with the learning of latent dynamics? We aim to investigate this question in this project, <em>2024</em>. </div> <div class="periodical"> </div> <div class="links"> <a href="/projects/latent_converger" class="btn btn-sm z-depth-0" role="button">Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/gdn-act-480.webp 480w,/assets/img/publication_preview/gdn-act-800.webp 800w,/assets/img/publication_preview/gdn-act-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/gdn-act.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="gdn-act.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="gdn-act" class="col-sm-8"> <div class="title">Novel Environment Transfer of Visuomotor Policy Via Object-Centric Domain-Randomization</div> <div class="author"> </div> <div class="periodical"> Proposed <b>GDN-ACT</b>, a novel, scalable approach that enables <b>zero-shot generalization</b> of visuomotor policies across unseen environments, using a pre-trained state-space mapping for object localization, <em>May</em> <em>2024</em>. </div> <div class="periodical"> </div> <div class="links"> <a href="/assets/pdf/gdn-act.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/gmot-480.webp 480w,/assets/img/publication_preview/gmot-800.webp 800w,/assets/img/publication_preview/gmot-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/gmot.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="gmot.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="gmot" class="col-sm-8"> <div class="title">Modular Gait Optimization: From Unit Moves to Multi-Step Trajectory in Bipedal Systems</div> <div class="author"> </div> <div class="periodical"> Proposed the Gait Modularization and Optimization Technique (GMOT), which leverages modular <b>unit gaits as initialization</b> for Hybrid Direct Collocation (HDC), reducing sensitivity to constraints and enhancing computational stability across various gaits, including walking, running, and hopping, <em>Dec</em> <em>2023</em>. </div> <div class="periodical"> </div> <div class="links"> <a href="/assets/pdf/gmot.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/QingquanBao/2DBiped" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/yvxaiver-480.webp 480w,/assets/img/publication_preview/yvxaiver-800.webp 800w,/assets/img/publication_preview/yvxaiver-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/yvxaiver.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="yvxaiver.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yvxaiver" class="col-sm-8"> <div class="title">Miniature City Autonomous Driving Platform Development with Real-Time Vision-Based Lane-Following</div> <div class="author"> </div> <div class="periodical"> Developed the drive stack for Washington University’s inaugural miniature city autonomous driving platform by developing the vision-based lane-following pipeline, <em>May</em> <em>2023</em>. </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/ggao22/yvxavier" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 George Jiayuan Gao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>